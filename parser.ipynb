{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree, html\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class parser():\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "        self.d = dict()\n",
    "    \n",
    "    def fetch(self,n):\n",
    "        r = requests.get(\"http://www.judicial.gov.tw/constitutionalcourt/p03_01_printpage.asp?expno={0}\".format(n))\n",
    "        self.tree = html.fromstring(r.content.decode(\"big5\"))\n",
    "        self.d = dict()\n",
    "        i = 1\n",
    "        while True:\n",
    "            try:\n",
    "                key =  self.tree.xpath(\"/html/body/center/table/tr/td/table/tr[2]/td/table/tr[{0}]/td[{1}]\".format(i,1))[0].text_content()\n",
    "                value =  self.tree.xpath(\"/html/body/center/table/tr/td/table/tr[2]/td/table/tr[{0}]/td[{1}]\".format(i,2))[0].text_content()\n",
    "                self.d[key]=value\n",
    "                i+=1\n",
    "            except IndexError:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# punctuations, strange characters\n",
    "stop = [line.strip().decode('utf-8') for line in open('stop_punc.txt').readlines() ]\n",
    "\n",
    "for n in range(573,690+1):\n",
    "    # the period chosen: 573 - 690 號解釋\n",
    "    p = parser()\n",
    "    try:\n",
    "        p.fetch(n)\n",
    "        pt = p.d[u'解釋文'] + p.d[u'理由書']\n",
    "        dt = [pt]\n",
    "    except:\n",
    "        dt = [\"\"]\n",
    "    \n",
    "    sep = []\n",
    "    for i in range(len(dt)):\n",
    "        words = [i for i in jieba.cut(dt[i])]\n",
    "        sep.append(\"\\t\".join(words))\n",
    "    sep_n = pd.Series(sep,name=\"sep\")\n",
    "    \n",
    "    sep_no_stop = []\n",
    "    for i in range(len(dt)):\n",
    "        words = sep_n[i].split('\\t')\n",
    "        text = \" \".join(list(set(words)-set(stop)))\n",
    "        sep_no_stop.append(text)\n",
    "    sep_f = pd.Series(sep_no_stop)\n",
    "    \n",
    "    sep_f.to_csv(\"test_d/sep_f_%s.txt\" %n, encoding=\"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
